---
title: "Temporal Split"
date: 2022-01-19
output: 
  github_document:
    html_preview: false
---

```{r setup, include=FALSE}
schtools::set_knitr_opts()
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE,
                      fig.path = 'figures/')
```

```{r deps}
library(here)
library(mikropml)
library(rlang)
library(tidyverse)
```

Investigate feasibility of doing a temporal split to train/test models on older data
and then validate on newer data. 
Bootstrap the test data to get empirical 95% CI.

Do the 20% most recent patients have the same proportion of severe cases as the 
other 80% of the patients?

```{r load_data}
metadat_full <- read_csv(here('data','process','cases_full_metadata.csv'))
metadat_int <- read_csv(here('data','process','cases_int_metadata.csv'))
```

```{r functions}
count_prop <- function(dat, colname, part) {
  dat %>% 
    count({{ colname }}) %>% 
    mutate(p = round(n / sum(n), 3)) %>% 
    mutate(partition = part) %>% 
    select(partition, p, {{ colname }}) %>% 
    pivot_wider(names_from = partition, values_from = p)
}
compare_props <- function(test_dat, train_dat, colname) {
  test <- test_dat %>% 
    count_prop({{ colname }}, 'test')
  train <- train_dat %>% 
    count_prop({{ colname }}, 'train')
  full_join(test, train) %>% 
    mutate(severity = paste(quo_name(enquo(colname)), {{ colname }}, sep = "_")
    ) %>% 
    select(severity, train, test)
}
```


```{r int_props}
test_dat_int <- metadat_int %>% 
  slice_max(order_by = collection_date, prop = 0.2)

train_dat_int <- metadat_int %>% 
  anti_join(test_dat_int)

nrow(test_dat_int)
nrow(train_dat_int)
nrow(metadat_int)

partitions_int <- bind_rows(
  compare_props(test_dat_int, train_dat_int, idsa),
  compare_props(test_dat_int, train_dat_int, attrib),
  compare_props(test_dat_int, train_dat_int, allcause)
) 

kable(partitions_int)
```

## try bootstrapping with rsample

```{r boot}
library(furrr)
library(mikropml)
library(rsample)

model <- readRDS(here('results/predict_idsa/taxlevel_OTU/metric_AUC/dataset_int/trainfrac_0.8/temporal-split/glmnet_100_model.Rds'))

test_dat <- read_csv(here('results/predict_idsa/taxlevel_OTU/metric_AUC/dataset_int/trainfrac_0.8/temporal-split/glmnet_100_test-data.csv'))

calc_perf <- function(split) {
   get_performance_tbl(
        model,
        analysis(split),
        outcome_colname = 'idsa',
        perf_metric_function = caret::multiClassSummary,
        perf_metric_name = 'AUC',
        class_probs = TRUE,
        method = 'glmnet',
        seed = 100
      ) %>% 
    select(-c(method, seed)) %>% 
    mutate(across(everything(), as.numeric)) %>% 
    pivot_longer(everything(), names_to = 'term', values_to = 'estimate')
}

boots <- bootstraps(test_dat, times = 10) %>% 
  mutate(perf = future_map(splits, ~ calc_perf(.x)))

int_pctl(boots, perf)
```

## Plot performance

```{r perf-95-ci}
perf_dat <- read_csv(here('results','temporal-split','performance_results.csv'))
perf_dat %>% 
  filter(term %in% c('cv_metric_AUC', "AUC")) %>% 
  mutate(term = case_when(term == 'cv_metric_AUC' ~ 'train AUROC',
                          term == 'AUC' ~ 'test AUROC',
                          TRUE ~ term)
  ) %>% 
  rename(estimate = .estimate,
         lower = .lower,
         upper = .upper) %>% 
  ggplot(aes(x = estimate, xmin = lower, xmax = upper, y = outcome, color = term)) +
  geom_pointrange(position = position_dodge(width = 0.1)) +
  schtools::theme_sovacool()
```

