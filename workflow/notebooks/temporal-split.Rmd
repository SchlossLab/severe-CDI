---
title: "Temporal Split"
date: "`r Sys.Date()`"
output: 
  github_document:
    html_preview: false
---

```{r setup, include=FALSE}
schtools::set_knitr_opts()
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE,
                      echo = TRUE,
                      fig.path = 'figures/',
                      dpi = 200)
```

```{r deps}
library(here)
library(knitr)
library(mikropml)
library(rlang)
library(schtools)
library(tidyverse)
```

Investigate feasibility of doing a temporal split to train/test models on older data
and then validate on newer data. 
Bootstrap the test data to get empirical 95% CI.

Do the 20% most recent patients have the same proportion of severe cases as the 
other 80% of the patients?

```{r load_data}
metadat_full <- read_csv(here('data','process','cases_full_metadata.csv'))
metadat_int <- read_csv(here('data','process','cases_int_metadata.csv'))
```

```{r functions}
count_prop <- function(dat, colname, part) {
  dat %>% 
    count({{ colname }}) %>% 
    mutate(p = round(n / sum(n), 3)) %>% 
    mutate(partition = part) %>% 
    select(partition, p, {{ colname }}) %>% 
    pivot_wider(names_from = partition, values_from = p)
}
compare_props <- function(test_dat, train_dat, colname) {
  test <- test_dat %>% 
    count_prop({{ colname }}, 'test')
  train <- train_dat %>% 
    count_prop({{ colname }}, 'train')
  full_join(test, train) %>% 
    mutate(severity = paste(quo_name(enquo(colname)), {{ colname }}, sep = "_")
    ) %>% 
    select(severity, train, test)
}
```


```{r int_props}
test_dat_int <- metadat_int %>% 
  slice_max(order_by = collection_date, prop = 0.2)

train_dat_int <- metadat_int %>% 
  anti_join(test_dat_int)

nrow(test_dat_int)
nrow(train_dat_int)
nrow(metadat_int)

partitions_int <- bind_rows(
  compare_props(test_dat_int, train_dat_int, idsa),
  compare_props(test_dat_int, train_dat_int, attrib),
  compare_props(test_dat_int, train_dat_int, allcause)
) 

kable(partitions_int)
```

## try bootstrapping with rsample

```{r boot}
library(furrr)
library(mikropml)
library(rsample)

model <- readRDS(here('results/predict_idsa/taxlevel_OTU/metric_AUC/dataset_int/trainfrac_0.8/temporal-split/glmnet_100_model.Rds'))

test_dat <- read_csv(here('results/predict_idsa/taxlevel_OTU/metric_AUC/dataset_int/trainfrac_0.8/temporal-split/glmnet_100_test-data.csv'))

calc_perf <- function(split) {
   get_performance_tbl(
        model,
        analysis(split),
        outcome_colname = 'idsa',
        perf_metric_function = caret::multiClassSummary,
        perf_metric_name = 'AUC',
        class_probs = TRUE,
        method = 'glmnet',
        seed = 100
      ) %>% 
    select(-c(method, seed)) %>% 
    mutate(across(everything(), as.numeric)) %>% 
    pivot_longer(everything(), names_to = 'term', values_to = 'estimate')
}

boots <- bootstraps(test_dat, times = 10) %>% 
  mutate(perf = future_map(splits, ~ calc_perf(.x)))

int_pctl(boots, perf) %>% kable()
```

## Plot performance

```{r temporal-split_perf-95-ci}
perf_dat <- read_csv(here('results','temporal-split','performance_results.csv'))
perf_temp_plot <- perf_dat %>% 
  filter(term %in% c('cv_metric_AUC', "AUC")) %>%
  mutate(term = case_when(term == 'cv_metric_AUC' ~ 'train AUROC',
                          term == 'AUC' ~ 'test AUROC',
                          TRUE ~ term)
  ) %>% 
  rename(estimate = .estimate,
         lower = .lower,
         upper = .upper) %>% 
  ggplot(aes(x = estimate, xmin = lower, xmax = upper, y = outcome, color = term)) +
  geom_vline(xintercept = 0.5, linetype = 'dashed') +
  geom_pointrange(position = position_dodge(width = 0.1)) +
  xlim(0,1) +
  facet_wrap('dataset', ncol = 1) +
  coord_flip() +
  labs(title = "Temporal split", 
       caption = 'Error bars: 95% CI from 10,000 bootstraps of the test set') +
  theme_sovacool() +
  theme(legend.position = 'top',
        axis.title.x = element_blank(),
        plot.caption = element_text(hjust = 0)
  )
perf_temp_plot 
```

### vs 100x train/test splits

```{r perf_100x}
perf_dat_100 <- data.table::fread(here('results', 
                                      'performance_results_aggregated.csv')
                                 ) %>% 
  filter(trainfrac == 0.8, taxlevel == 'OTU') %>% 
  pivot_longer(c('cv_metric_AUC', "AUC"), 
               names_to = '.term', values_to = '.estimate') %>% 
  mutate(.term = case_when(.term == 'cv_metric_AUC' ~ 'train_AUROC',
                          .term == 'AUC' ~ 'test_AUROC',
                          TRUE ~ .term)
         ) %>% 
  select(method, seed, outcome, taxlevel, metric, dataset, trainfrac, .term, .estimate) %>% 
  filter(!is.na(.estimate))

perf_dat_100 %>% 
  group_by(dataset, outcome, .term) %>% 
  summarize(median_est = round(median(.estimate),3)) %>% 
  pivot_wider(names_from = dataset, values_from = median_est, names_prefix = 'median_perf_') %>% 
  kable()
  
```
```{r perf_100_glmnet}
perf_100_glmnet_plot <- perf_dat_100 %>% 
  ggplot(aes(x = .estimate, y = outcome, color = .term)) +
  geom_vline(xintercept = 0.5, linetype = 'dashed') +
  geom_boxplot() +
  xlim(0,1) +
  facet_wrap('dataset', ncol = 1) +
  coord_flip() +
  labs(title = '100x train/test splits - glmnet',
       caption = 'Box: interquartile range. Whisker: min & max') +
  theme_sovacool() +
  theme(legend.position = 'top',
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.caption = element_text(hjust = 0)
  )
perf_100_glmnet_plot
```
```{r, perf_100_rf}
perf_100_rf_plot <- perf_dat_100 %>% 
  filter(method == 'rf') %>% 
  ggplot(aes(x = .estimate, y = outcome, color = .term)) +
  geom_vline(xintercept = 0.5, linetype = 'dashed') +
  geom_boxplot() +
  xlim(0,1) +
  facet_wrap('dataset', ncol = 2) +
  labs(title = '100x train/test splits - rf',
       caption = 'Box: interquartile range. Whisker: min & max') +
  theme_sovacool() +
  theme(legend.position = 'top',
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.caption = element_text(hjust = 0)
  )
perf_100_rf_plot
```
```{r perf_temporal_vs_100, fig.width=10, fig.height=5}
cowplot::plot_grid(perf_temp_plot, perf_100_glmnet_plot, nrow = 1)
```


## Computational resources

```{r temporal-split_bench}
bench_dat <- read_csv(here('results','temporal-split','benchmarks_results.csv'))
bench_dat %>% 
  ggplot(aes(x = s, y = outcome, color = dataset)) +
  geom_point() +
  scale_x_time() +
  theme_sovacool()
```

## Feature importance

```{r temporal-split_feat-imp}
feat_dat <- read_csv(here('results','temporal-split','feature-importance_results.csv'))
tax_dat <- read_tax(here('data','mothur','cdi.taxonomy'))
important_feats <- feat_dat %>% 
  rename(otu = names) %>% 
  left_join(tax_dat, by = 'otu') %>% 
  filter(pvalue < 0.05, perf_metric_diff > 0) %>% 
  arrange(perf_metric_diff)
important_feats %>% 
  mutate(otu = factor(otu, levels = important_feats %>% pull(otu) %>% unique())) %>% 
  ggplot(aes(x = perf_metric_diff, y = label_html, color = outcome, shape = dataset)) +
  geom_point() +
  theme_sovacool() +
  theme(axis.text.y = ggtext::element_markdown())
```

