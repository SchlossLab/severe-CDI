---
title: "Predicting _C. difficile_ Infection Severity from the Taxonomic Composition of the Gut Microbiome"
bibliography: references.bib
fontsize: 11pt
date: last-modified
date-format: medium
format:
  manuscript-pdf:
    mainfont: Helvetica
    keep-tex: true
    linenumbers: true
    doublespacing: true
    lof: false
  html:
    embed-resources: true
runningtitle: Predicting CDI Severity from OTUs
runningauthor: Sovacool
papertype: Preprint
author:
  - name: Kelly L. Sovacool
    orcid: 0000-0003-3283-829X
    affiliations:
      - ref: bioinf
  - name: Sarah E. Tomkovich
    affiliations:
      - ref: micro
  - name: Megan L. Coden
    affiliations:
      - ref: mcdb
  - name: Vincent B. Young
    affiliations:
      - ref: micro
      - ref: intmed
  - name: Krishna Rao
    affiliations:
      - ref: intmed
  - name: Patrick D. Schloss
    orcid: 0000-0002-6935-4275
    email: pschloss@umich.edu
    corresponding: true
    affiliations:
      - ref: micro
      - ref: ccmb
affiliations:
  - id: bioinf
    name: Department of Computational Medicine & Bioinformatics, University of Michigan
  - id: micro
    name: Department of Microbiology & Immunology, University of Michigan
  - id: mcdb
    name: Department of Molecular, Cellular, and Developmental Biology, University of Michigan
  - id: intmed
    name: Division of Infectious Diseases, Department of Internal Medicine, University of Michigan
  - id: ccmb
    name: Center for Computational Medicine and Bioinformatics, University of Michigan
abstract: TODO
importance: TODO
keywords: _C. difficile_ infection, supervised machine learning, gut microbiome, amplicion sequencing
---

# Introduction

A few ways to define CDI severity (@fig-flowchart)

# Results

## Model performance

Report median AUROC for training set and test set, and median AUBPRC for test set (@fig-performance).

## Feature importance

Most important OTUs contributing to model performance (@fig-features)

## Clinical value of severity prediction models

# Discussion

TODO

# Materials and Methods

## Sample collection

This study was approved by the University of Michigan Institutional Review
Board. All patient samples were collected by the University of Michigan Health
System from January 2016 through December 2017.
Stool samples that had unformed stool consistency were tested for *C. difficile* by
the clinical microbiology lab with a two-step algorithm that included detection
of *C. difficile* glutamate dehydrogenase and toxins A and B by enzyme
immunoassay with reflex to PCR for the *tcdB* gene when results were discordant.
1,517 stool samples were collected from patients diagnosed with a CDI.
Leftover stool samples that were sent to the clinical microbiology lab were
collected and split into different aliquots.
For 16S sequencing, the aliquot of stool was resuspended in
DNA genotek stabilization buffer and then stored in the -80&deg;C freezer.
Only the first CDI sample per patient was used for subsequent ML analyses such
that no patient is represented more than once, resulting in a dataset of 1,191
samples.

## 16S rRNA gene amplicon sequencing

Samples stored in DNA genotek buffer were thawed from the -80&deg;C, vortexed,
and then transferred to a 96-well bead beating plate for DNA extractions.
DNA was extracted using the DNeasy
Powersoil HTP 96 kit (Qiagen) and an EpMotion 5075 automated pipetting system
(Eppendorf).
The V4 region of the 16S rRNA gene was amplified with the AccuPrime
Pfx DNA polymerase (Thermo Fisher Scientific) using custom barcoded primers, as
previously described [@kozich_development_2013].
Each library preparation plate for
sequencing contained a negative control (water) and mock community control
(ZymoBIOMICS microbial community DNA standards).
The PCR amplicons were
normalized (SequalPrep normalizatin plate kit from Thermo Fisher Scientific),
pooled and quantified (KAPA library quantification kit from KAPA Biosystems),
and sequenced with the MiSeq system (Illumina).

All sequences were processed with mothur (v1.46) using the MiSeq SOP protocol
[@schloss_introducing_2009; @kozich_development_2013].
Paired sequencing reads were combined and
aligned with the SILVA (v132) reference database [@quast_silva_2013] and taxonomy was
assigned with a modified version of the Ribosomal Database Project reference
sequences (v16) [@cole_ribosomal_2014].
Sequences were clustered into _de novo_ OTUs with the OptiClust algorithm in
mothur [@westcott_opticlust_2017].
Samples were rarefied to 5,000 sequences per sample, repeated 1,000
times for alpha and beta diversity analysis.
<!-- TODO supplementary figure with alpha and beta diversity & significance -->

## Defining CDI severity

IDSA definition of severe CDI based on lab values.
CDC definiton of severe CDI based on disease-related complications [@mcdonald_recommendations_2007].

## Model training and evaluation

Random forest models were used to examine whether OTU data collected on the day
of diagnosis could classify CDI cases as severe according to four different
definitons of severity.
We used the mikropml R package v1.5.0 [@topcuoglu_mikropml_2021]
for all steps of the machine learning analysis.
We randomly split the data into an 80% training and 20% test set and repeated
this 100 times, followed by training models with 5-fold cross-validation.
Model performance was calculated on the test set using the area under the
receiver-operator characteristic curve (AUROC) and the Area under the balanced
precision-recall curve (AUBPRC).
Permutation feature importance was then performed to determine which OTUs
contributed most to model performance.
We reported OTUs with a significant permutation test in at least 80 of the 100
models.

Since the severity labels are imbalanced with different frequencies of severity
for each definition, we calculated balanced precision, the precision expected if
the labels were balanced.
The balanced precision and Area under the balanced precision-recall curve (AUBPRC)
were calculated with Equations 1 and 7 from @wu_improved_2021.

## Code availability

The complete workflow, code, and supporting files required to reproduce this
manuscript with accompanying figures is available at
<https://github.com/SchlossLab/severe-CDI>.
<!-- TODO update GitHub URL once accepted to journal -->

The workflow was defined with Snakemake [@koster_snakemake_2012] using a custom
version of the mikropml Snakemake workflow [@sovacool_mikropml_2023].
Dependencies were managed with conda environments.
Scripts were written in R [@r_core_team_r_2020],
Python [@van_rossum_python_2009],
and GNU bash.
Additional software and packages used in the creation of this manuscript include
cowplot [@wilke_cowplot_2020],
ggtext [@wilke_ggtext_2020],
ggsankey [@sjoberg_ggsankey_2022],
schtools [@sovacool_schtools_2022],
the tidyverse metapackage [@wickham_welcome_2019],
Quarto, and
vegan [@oksanen_vegan_2023].

## Data availability

The 16S rRNA sequencing data have been deposited in the National Center for
Biotechnology Information Sequence Read Archive
(BioProject Accession no. PRJNA729511).

# Acknowledgements

TODO

# References {.unnumbered}

::: {#refs}
:::

# Figures

::: {#fig-flowchart fig-cap="**CDI severity definitions.**
A) Decision flow chart to define CDI cases as severe according to the Infectious Diseases Society of America (IDSA) based on lab values,
the occurence of complications due to any cause (All-cause),
and the occurence of disease-related complications confirmed as attributable to CDI with chart review (Attrib).
B) The proportion of severe CDI cases labelled according to each definition.
An additional 'Pragmatic' severity definition uses the Attributable definition when possible,
and falls back to the All-cause definition when chart review is not available.
<!-- TODO table (supplementary?) showing counts & frequency of positives-->
"}
![](figures/flowchart_sankey.png)
:::

::: {#fig-performance fig-cap="**Performance of ML models.**
Area under the receiver-operator characteristic curve (AUROC) for the test sets
and cross-validation folds of the training sets,
and the Area under the balanced precision-recall curve (AUBPRC) for the test sets.
Left: models were trained on the full dataset, with different numbers of samples available for each severity definition.
Right: models were trained on the intersection of samples with all labels available for each definition.
<!-- TODO add plots of AUROC and AUBPRC curves -->
"}
![](figures/ml-performance.png)
:::

::: {#fig-features fig-cap="**Feature importance.**
Feature importance via permutation test.
For each OTU, the order of samples was randomized in the test set 100 times and
the performance was re-calculated to estimate the permutation performance.
An OTU was considered important if the performance decreased when the OTU was
permuted in at least 80% of the models.
OTUs with a greater difference in AUROC (actual performance minus permutation performance)
are more important.
Left: models were trained on the full dataset, with different numbers of samples available for each severity definition.
Right: models were trained on the intersection of samples with all labels available for each definition.
"}
![](figures/feature-importance.png)
:::
